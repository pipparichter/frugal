{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a8c3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUPPLEMENT\n",
    "\n",
    "# CLAIM: It likely that spurious gene boundaries only explain a small subset of the conflicts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7fed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "from src.files import BLASTJsonFile\n",
    "from src.reference import annotate\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import mannwhitneyu\n",
    "from utils import * \n",
    "from src.tools import RNACoFold\n",
    "import matplotlib as mpl\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c777d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_CODONS = ['AUG', 'GUG', 'UUG']\n",
    "STOP_CODONS = ['UAA', 'UAG', 'UGA']\n",
    "MIN_LENGTH = 30 # Minimum allowed sequence length, in amino acids.\n",
    "\n",
    "\n",
    "get_num_resolved = lambda df : len(df[df.overlap_length == 0].drop_duplicates(['query_id', 'top_hit_id']))\n",
    "\n",
    "# is_annotated_match = lambda df : df.match & (df.top_hit_product != 'hypothetical protein') & (~df.top_hit_pseudo)\n",
    "is_annotated_match = lambda df : df.match & (df.top_hit_product != 'hypothetical protein') & (~df.top_hit_pseudo) & (df.top_hit_evidence_type == 'similar to AA sequence')\n",
    "is_annotated_exact_match = lambda df : df.exact_match & (df.top_hit_product != 'hypothetical protein') & (~df.top_hit_pseudo) & (df.top_hit_evidence_type == 'similar to AA sequence')\n",
    "is_n_terminal_extension = lambda df : (((df.query_start < df.top_hit_start) & (df.query_strand  == 1)) | ((df.query_stop > df.top_hit_stop) & (df.query_strand  == -1))) & df.match\n",
    "is_c_terminal_extension = lambda df : (((df.query_start < df.top_hit_start) & (df.query_strand  == -1)) | ((df.query_stop > df.top_hit_stop) & (df.query_strand  == 1))) & df.match\n",
    "is_annotated_n_terminal_extension = lambda df : is_n_terminal_extension(df) & is_annotated_match(df)\n",
    "is_overlap_at_n_terminus = lambda overlap, strand : ((overlap == '01') and (strand == -1)) or ((overlap == '10') and (strand == 1))\n",
    "is_overlap_at_c_terminus = lambda overlap, strand : ((overlap == '01') and (strand == 1)) or ((overlap == '10') and (strand == -1))\n",
    "\n",
    "is_nested = lambda df : ((df.top_hit_overlap == '11') | (df.query_overlap == '11')) & is_cds_conflict(df)\n",
    "\n",
    "\n",
    "def get_n_terminal_extension_length(row):\n",
    "    try:\n",
    "        assert row.match and (not row.exact_match), f'get_n_terminal_extension_length: Top hit and query sequences should be non-exact matches.'\n",
    "        assert ((row.query_start < row.top_hit_start) and (row.query_strand  == 1)) or ((row.query_stop > row.top_hit_stop) and (row.query_strand  == -1)), f'get_n_terminal_extension_length: There is no extension.'\n",
    "    except:\n",
    "        return 0 \n",
    "    \n",
    "    if row.query_strand == 1:\n",
    "        length = row.top_hit_start - row.query_start\n",
    "    elif row.query_strand == -1:\n",
    "        length = row.query_stop - row.top_hit_stop\n",
    "    # This condition doesn't always hold when there is an assembly gap. \n",
    "    # assert (length % 3) == 0, f'get_n_terminal_extension_length: Extension length should be divisible by 3, got {length}.'\n",
    "    return length / 3\n",
    "\n",
    "\n",
    "def get_alternate_starts(nt_seq:str=None, codon_start:int=1, start_codons:list=['AUG', 'GUG']):\n",
    "    \n",
    "    nt_seq = nt_seq[int(codon_start) - 1:]\n",
    "    \n",
    "    codons = np.array([nt_seq[i:i + 3] for i in range(0, len(nt_seq) + 1, 3)])\n",
    "    start_idxs = list(np.where(np.isin(codons, start_codons))[0])\n",
    "    # WP_259095463.1 does not seem to have a start codon?\n",
    "    if len(start_idxs) == 0:\n",
    "        return [0]\n",
    "    \n",
    "    assert len(''.join(codons)) == len(nt_seq), 'get_alternate_starts: Joined codons should have the same length as the original nucleotide sequence.'\n",
    "\n",
    "    if 0 not in start_idxs:\n",
    "        start_idxs = [0] + start_idxs\n",
    "\n",
    "    return start_idxs\n",
    "\n",
    "\n",
    "def get_alternate_stops(id_, seq:str=None, blast_df:pd.DataFrame=None, min_percent_identity:float=0.8):\n",
    "\n",
    "    stop_idxs = [len(seq)]\n",
    "\n",
    "    blast_df = blast_df[(blast_df.subject_alignment_start < 3) | (blast_df.query_alignment_start < 3)].copy() # Make sure alignment starts at the N-termini, allowing alternate start selection.\n",
    "    blast_df = blast_df[(blast_df.subject_length - blast_df.subject_alignment_stop < 3)].copy() # Make sure alignment extends to the subject C-terminus of the subject. \n",
    "    blast_df = blast_df[blast_df.percent_identity > min_percent_identity].copy() # Make sure alignment extends to the subject C-terminus of the subject. \n",
    "\n",
    "    df = blast_df[blast_df.index == id_].copy()\n",
    "    df['truncation_length'] = df.query_length - df.query_alignment_stop\n",
    "    df = df[df.truncation_length > 0].copy()\n",
    "    df = df[(df.query_length - df.truncation_length) > MIN_LENGTH].copy() # Make sure the C-terminally truncated sequence meets the minimum length. \n",
    "    \n",
    "    return stop_idxs + list(df.query_length - df.truncation_length) # Make sure to include the \"no truncation\" case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2372de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('../data/results/results-2/dataset.csv', index_col=0)\n",
    "\n",
    "dataset_df = annotate(dataset_df)\n",
    "dataset_df['query_codon_start'] = 1\n",
    "dataset_df['query_id'] = dataset_df.index\n",
    "dataset_df['query_product'] = 'none'\n",
    "dataset_df['query_rbs_motif'] = ~(dataset_df.query_rbs_motif.str.contains('T') |( dataset_df.query_rbs_motif == 'none'))\n",
    "dataset_df['query_seq'] = dataset_df.seq\n",
    "dataset_df['query_length'] = dataset_df.seq.apply(len) # Make sure these are in units of amino acids. \n",
    "dataset_df['top_hit_length'] = dataset_df.top_hit_seq.apply(len) # Make sure these are in units of amino acids. \n",
    "dataset_df['top_hit_id'] = dataset_df.top_hit_protein_id\n",
    "dataset_df['top_hit_gc_content'] = dataset_df.top_hit_nt_seq.apply(get_gc_content)\n",
    "dataset_df['query_seq'] = dataset_df.seq\n",
    "\n",
    "# Exclude genomes on which Prodigal did horrifically (I think I needed to use a different translation table). \n",
    "# Also, one of the excluded genomes belongs to an endosymbiont which is not assigned a phylum.\n",
    "exclude_genome_ids = ['GCF_029854295.1', 'GCF_021057185.1', 'GCF_016097415.1'] \n",
    "dataset_df = dataset_df[~dataset_df.genome_id.isin(exclude_genome_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed2c451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. CDS conflicts: 483\n",
      "Num. non-nested CDS conflicts: 398\n"
     ]
    }
   ],
   "source": [
    "print('Num. CDS conflicts:', is_cds_conflict(dataset_df).sum())\n",
    "print('Num. non-nested CDS conflicts:', (is_cds_conflict(dataset_df) & ~is_nested(dataset_df)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e3b3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shared_blast_hit(row, blast_df:pd.DataFrame=None, min_percent_identity:float=0.8):\n",
    "    blast_df = blast_df[(blast_df.bit_score > 50) & (blast_df.percent_identity > min_percent_identity)].copy()\n",
    "\n",
    "    shared_subject_ids = np.array([])\n",
    "    if (row.query_id in blast_df.index) and row.top_hit_id in blast_df.index:\n",
    "        shared_subject_ids = np.intersect1d(blast_df.loc[row.top_hit_id].subject_id, blast_df.loc[row.query_id].subject_id)\n",
    "    if len(shared_subject_ids) == 0:\n",
    "        return None\n",
    "    # if len(shared_subject_ids) > 0:\n",
    "    #     print(f'get_shared_blast_hit: Multiple shared BLAST hits for {row.query_id} and {row.top_hit_id}.')\n",
    "\n",
    "    get_bit_score = lambda query_id, subject_id : blast_df[(blast_df.index == query_id) & (blast_df.subject_id == subject_id)].bit_score.iloc[0]\n",
    "    get_percent_identity = lambda query_id, subject_id : blast_df[(blast_df.index == query_id) & (blast_df.subject_id == subject_id)].percent_identity.iloc[0]\n",
    "    shared_subject_scores = [get_percent_identity(row.query_id, subject_id) + get_percent_identity(row.top_hit_id, subject_id) for subject_id in shared_subject_ids]\n",
    "    # shared_subject_scores = [get_bit_score(row.query_id, subject_id) + get_bit_score(row.top_hit_id, subject_id) for subject_id in shared_subject_ids]\n",
    "    shared_subject_ids = shared_subject_ids[np.argsort(shared_subject_scores)]\n",
    "    return shared_subject_ids[-1] # Return the shared ID with the highest mean bit score. \n",
    "\n",
    "def is_fragmented(row, blast_df:pd.DataFrame=None, min_percent_identity:float=0.8):\n",
    "    return get_shared_blast_hit(row, blast_df=blast_df, min_percent_identity=min_percent_identity) is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aff4b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering the tandem configuration, errors which can result in hallucinated overlap are:\n",
    "# (1) N-terminal (5') extension of the downstream gene; this is the most common (57% of overlaps > 60 bp)\n",
    "# (2) Gene fragmentation due to a frameshift (23% of overlaps > 60 bp)\n",
    "# (3) C-terminal (3') extension of the upstream gene due to frameshift at the 3' end or a mutation in the stop codon (9.5% of overlaps > 60 bp)\n",
    "# (4) A combination of (1) and (3) (10% of overlaps > 60 bp)\n",
    "\n",
    "# https://pmc.ncbi.nlm.nih.gov/articles/PMC2478687/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cd67d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. tandem conflicts: 231\n",
      "write_fasta: Wrote 462 sequences to ../data/results/results-2/conflict_tandem.faa\n",
      "Num. tandem overlaps due to fragmentation: 25\n",
      "\n",
      "['NZ_JAALLS010000037.1_4', 'NZ_JAALLS010000005.1_1', 'NZ_JAYGHR010000002.1_180', 'NZ_JAYGHR010000010.1_46', 'NZ_JAYGHR010000095.1_4', 'NC_021487.1_586', 'NZ_JAIKTU010000005.1_51', 'NZ_QXIU01000121.1_2', 'NZ_QXIU01000013.1_4', 'NZ_QXIU01000201.1_20', 'NZ_QXIU01000258.1_3', 'NZ_QXIU01000037.1_8', 'NZ_QXIU01000048.1_21', 'NZ_QXIU01000073.1_4', 'NZ_QXIU01000088.1_2', 'NZ_AP025523.1_1853', 'NZ_AP025523.1_2690', 'NZ_CP130454.1_336', 'NZ_CP130454.1_2358', 'NZ_CP130454.1_3138', 'NZ_CP130454.1_3168', 'NC_015499.1_1072', 'NC_014960.1_288', 'NC_014960.1_2737', 'NZ_AP035449.1_1439']\n"
     ]
    }
   ],
   "source": [
    "# Tandem overlaps \n",
    "\n",
    "tandem_dataset_df = dataset_df[is_cds_conflict(dataset_df) & (dataset_df.overlap_type == 'tandem') & (~is_nested(dataset_df))].copy()\n",
    "print('Num. tandem conflicts:', len(tandem_dataset_df))\n",
    "write_fasta(tandem_dataset_df, path='../data/results/results-2/conflict_tandem.faa')\n",
    "# BLASTp against NCBI clustered nr database, with the following parameters:\n",
    "# Max. target sequences     10\n",
    "# Expect threshold      0.005\n",
    "tandem_blast_df = BLASTJsonFile('../data/results/results-2/conflict_tandem_blast.json').to_df()\n",
    "\n",
    "tandem_dataset_df['fragmented'] = tandem_dataset_df.apply(lambda row : is_fragmented(row, blast_df=tandem_blast_df), axis=1)\n",
    "print('Num. tandem overlaps due to fragmentation:', tandem_dataset_df.fragmented.sum(), end='\\n\\n')\n",
    "\n",
    "tandem_fragmented_ids = list(tandem_dataset_df[tandem_dataset_df.fragmented].index)\n",
    "print(tandem_fragmented_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfbdb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure(dataset_df:pd.DataFrame, blast_df:pd.DataFrame=tandem_blast_df, fragmented_ids=tandem_fragmented_ids):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, len(fragmented_ids)))\n",
    "\n",
    "    def get_overlap_termini(id_):\n",
    "        prefix = 'top_hit' if (id_[0] == 'W') else 'query'\n",
    "        overlap = dataset_df[dataset_df[f'{prefix}_id'] == id_][f'{prefix}_overlap'].iloc[0]\n",
    "        strand = dataset_df[dataset_df[f'{prefix}_id'] == id_][f'{prefix}_strand'].iloc[0]\n",
    "        # assert overlap != '11', f'get_overlap_terminus: Not expecting a nested overlap, but got {overlap} for {id_}.'\n",
    "        if ((overlap == '01') and (strand == 1)) or ((overlap == '10') and (strand == -1)):\n",
    "            return [-1]\n",
    "        elif ((overlap == '01') and (strand == -1)) or ((overlap == '10') and (strand == 1)):\n",
    "            return [0]\n",
    "        elif (overlap == '11'):\n",
    "            return [-1, 0]\n",
    "\n",
    "    y_ticks, y_tick_labels = list(), list()\n",
    "    for i, row in enumerate(dataset_df.loc[fragmented_ids].itertuples()):\n",
    "        shared_id = get_shared_blast_hit(row, blast_df=blast_df)\n",
    "        \n",
    "        offset = -0.25\n",
    "        y_ticks.append(i)\n",
    "        y_tick_labels.append(blast_df[blast_df.subject_id == shared_id].subject_description.iloc[0])\n",
    "        \n",
    "        for row_ in blast_df[blast_df.index.isin([row.top_hit_id, row.query_id]) & (blast_df.subject_id == shared_id)].itertuples():\n",
    "\n",
    "            query_length_before_alignment = row_.query_alignment_start\n",
    "            query_length_after_alignment = row_.query_length - row_.query_alignment_start\n",
    "            query_start, query_stop = row_.subject_alignment_start - query_length_before_alignment, row_.subject_alignment_stop + query_length_after_alignment\n",
    "\n",
    "            y_ticks.append(i + offset)\n",
    "            y_tick_labels.append(row_.Index)\n",
    "\n",
    "            ax.hlines(i, xmin=0, xmax=row_.subject_length, color='black')\n",
    "            ax.hlines(i + offset, xmin=query_start, xmax=query_stop, color='black', ls='--', lw=0.5)\n",
    "            ax.hlines(i + offset, xmin=row_.subject_alignment_start, xmax=row_.subject_alignment_stop, color='darkseagreen', lw=2)\n",
    "\n",
    "            for terminus in get_overlap_termini(row_.Index):\n",
    "                ax.scatter([(query_start, query_stop)[terminus]], [i + offset], color='indianred', zorder=100, s=3)\n",
    "            offset -= 0.25\n",
    "\n",
    "    ax.set_yticks(y_ticks, labels=y_tick_labels)\n",
    "    for edge in ['top', 'left', 'right']:\n",
    "        ax.spines[edge].set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# figure(tandem_dataset_df, blast_df=tandem_blast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384966d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's not always clear which sequence in the conflicting pair should be modified. In preliminary attempts, it seems as though the\n",
    "# wrong sequence may have been truncated, so it's safer to account for both rather than simply pick the configuration with the smallest\n",
    "# truncation length. \n",
    "\n",
    "def get_best_configurations(df:pd.DataFrame):\n",
    "    conditions = [(df.top_hit_terminus != 'none') & (df.query_terminus != 'none'), (df.top_hit_terminus == 'none') & (df.query_terminus == 'none'), (df.top_hit_terminus == 'none') & (df.query_terminus != 'none'), (df.top_hit_terminus != 'none') & (df.query_terminus == 'none')]\n",
    "    modifications = ['both', 'none', 'query', 'top_hit']\n",
    "    df['modification'] = np.select(conditions, modifications, default='error')\n",
    "\n",
    "    df = df[((df.query_seq.apply(len) > MIN_LENGTH) & (df.top_hit_seq.apply(len) > MIN_LENGTH)) | (df.modification == 'none')].copy()\n",
    "    # df = df[df.total_truncation_length > 0].copy() # Only include things that could actually be adjusted.\n",
    "    df = df.sort_values(['overlap_length', 'total_truncation_length'], ascending=True) # Select options which minimize total truncation length.\n",
    "    df = df.drop_duplicates('modification', keep='first')\n",
    "\n",
    "    assert ('error' not in df.modification.values.tolist()), 'get_best_configurations: At least one conflict was not assigned a modification category.'\n",
    "    assert ('none' in df.modification.values.tolist()), 'get_best_configurations: There should be an unmodified conflict in the DataFrame.'\n",
    "\n",
    "    return [df.iloc[i] for i in range(len(df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26a71d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tandem_adjusted_conflict_df = list()\n",
    "\n",
    "for row in [row.to_dict() for _, row in tandem_dataset_df[~tandem_dataset_df.fragmented].iterrows()]:\n",
    "\n",
    "    downstream_prefix = 'top_hit' if is_overlap_at_n_terminus(row['top_hit_overlap'], row['top_hit_strand']) else 'query'\n",
    "    upstream_prefix = 'top_hit' if is_overlap_at_c_terminus(row['top_hit_overlap'], row['top_hit_strand']) else 'query'\n",
    "\n",
    "    start_idxs = get_alternate_starts(row[f'{downstream_prefix}_nt_seq'], codon_start=row[f'{downstream_prefix}_codon_start'])\n",
    "    stop_idxs = get_alternate_stops(row[f'{upstream_prefix}_id'], seq=row[f'{upstream_prefix}_seq'], blast_df=tandem_blast_df)\n",
    "\n",
    "    df = list()\n",
    "    for start_idx in start_idxs:\n",
    "        for stop_idx in stop_idxs:\n",
    "            info = {'query_id':row['query_id'], 'top_hit_id':row['top_hit_id']}\n",
    "            info[f'{upstream_prefix}_seq'] = row[f'{upstream_prefix}_seq'][:stop_idx]\n",
    "            info[f'{downstream_prefix}_seq'] = row[f'{downstream_prefix}_seq'][start_idx:]\n",
    "            info[f'{upstream_prefix}_nt_seq'] = row[f'{upstream_prefix}_nt_seq'][:stop_idx * 3]\n",
    "            info[f'{downstream_prefix}_nt_seq'] = row[f'{downstream_prefix}_nt_seq'][start_idx * 3:]\n",
    "            info[f'{upstream_prefix}_truncation_length'] = len(row[f'{upstream_prefix}_seq']) - len(info[f'{upstream_prefix}_seq'])\n",
    "            info[f'{downstream_prefix}_truncation_length'] = len(row[f'{downstream_prefix}_seq']) - len(info[f'{downstream_prefix}_seq'])\n",
    "            info['overlap_length'] = max(0, row['overlap_length'] - 3 * (info['query_truncation_length'] + info['top_hit_truncation_length']))\n",
    "            info['original_overlap_length'] = row['overlap_length']\n",
    "            info['total_truncation_length'] = info['query_truncation_length'] + info['top_hit_truncation_length']\n",
    "            info[f'{downstream_prefix}_terminus'] = 'N' if (start_idx > 0) else 'none'\n",
    "            info[f'{upstream_prefix}_terminus'] = 'C' if (stop_idx < len(row[f'{upstream_prefix}_seq'])) else 'none'\n",
    "            df.append(info)\n",
    "\n",
    "    tandem_adjusted_conflict_df += get_best_configurations(pd.DataFrame(df))\n",
    "\n",
    "tandem_adjusted_conflict_df = pd.DataFrame(tandem_adjusted_conflict_df)\n",
    "# tandem_adjusted_conflict_df = pd.concat(tandem_adjusted_conflict_df)\n",
    "\n",
    "tandem_adjusted_conflict_df['n_terminal_truncation'] = ((tandem_adjusted_conflict_df.query_terminus == 'N') | (tandem_adjusted_conflict_df.top_hit_terminus == 'N')) & (tandem_adjusted_conflict_df.modification != 'both')\n",
    "tandem_adjusted_conflict_df['c_terminal_truncation'] = ((tandem_adjusted_conflict_df.query_terminus == 'C') | (tandem_adjusted_conflict_df.top_hit_terminus == 'C')) & (tandem_adjusted_conflict_df.modification != 'both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f955d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. tandem overlaps resolved: 133\n",
      "Num. tandem overlaps resolved by N-terminal truncation: 118\n",
      "Num. tandem overlaps resolved by C-terminal truncation: 27\n",
      "Num. tandem overlaps resolved by truncation at both termini: 21\n"
     ]
    }
   ],
   "source": [
    "print('Num. tandem overlaps resolved:', get_num_resolved(tandem_adjusted_conflict_df))\n",
    "print('Num. tandem overlaps resolved by N-terminal truncation:', get_num_resolved(tandem_adjusted_conflict_df[tandem_adjusted_conflict_df.n_terminal_truncation]))\n",
    "print('Num. tandem overlaps resolved by C-terminal truncation:', get_num_resolved(tandem_adjusted_conflict_df[tandem_adjusted_conflict_df.c_terminal_truncation]))\n",
    "print('Num. tandem overlaps resolved by truncation at both termini:', get_num_resolved(tandem_adjusted_conflict_df[tandem_adjusted_conflict_df.modification == 'both']))\n",
    "\n",
    "# categories = ['fragmented', 'n_terminal_extension', 'c_terminal_extension']\n",
    "# tandem_dataset_df['category'] = np.select([tandem_dataset_df[category] for category in categories], categories, default='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51a1b947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. convergent conflicts: 134\n",
      "write_fasta: Wrote 268 sequences to ../data/results/results-2/conflict_convergent.faa\n"
     ]
    }
   ],
   "source": [
    "# Convergent overlaps\n",
    "\n",
    "# Convergent overlaps conflict at the 3' end of both genes, so could only be hallucinated by 3' extension of one or both genes. \n",
    "# The best way to assess the likelihood of a 3' extension is by searching for orthologs which align at the 5' end. \n",
    " \n",
    "convergent_dataset_df = dataset_df[is_cds_conflict(dataset_df) & (dataset_df.overlap_type == 'convergent') & (~is_nested(dataset_df))].copy()\n",
    "print('Num. convergent conflicts:', len(convergent_dataset_df))\n",
    "\n",
    "write_fasta(convergent_dataset_df, path='../data/results/results-2/conflict_convergent.faa')\n",
    "\n",
    "# BLASTp against NCBI clustered nr database, with the following parameters:\n",
    "# Max. target sequences     10\n",
    "# Expect threshold      0.005\n",
    "convergent_blast_df = BLASTJsonFile('../data/results/results-2/conflict_convergent_blast.json').to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9b38b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. resolved convergent overlaps: 25\n"
     ]
    }
   ],
   "source": [
    "convergent_adjusted_conflict_df = list()\n",
    "\n",
    "for row in convergent_dataset_df.itertuples():\n",
    "\n",
    "    df = list()\n",
    "    for query_stop_idx in get_alternate_stops(row.query_id, seq=row.query_seq, blast_df=convergent_blast_df):\n",
    "        for top_hit_stop_idx in get_alternate_stops(row.top_hit_id, seq=row.top_hit_seq, blast_df=convergent_blast_df):\n",
    "            info = {'query_id':row.query_id, 'top_hit_id':row.top_hit_id}\n",
    "            info['query_seq'] = row.query_seq[:query_stop_idx]\n",
    "            info['top_hit_seq'] = row.top_hit_seq[:top_hit_stop_idx]\n",
    "            info['query_nt_seq'] = row.query_nt_seq[:3 * query_stop_idx]\n",
    "            info['top_hit_nt_seq'] = row.top_hit_nt_seq[:3 * top_hit_stop_idx]\n",
    "            info[f'query_truncation_length'] = len(row.query_seq) - len(info['query_seq'])\n",
    "            info[f'top_hit_truncation_length'] = len(row.top_hit_seq) - len(info['top_hit_seq'])\n",
    "            info['overlap_length'] = max(0, row.overlap_length - 3 * (info['query_truncation_length'] + info['top_hit_truncation_length']))\n",
    "            info['original_overlap_length'] = row.overlap_length\n",
    "            info['total_truncation_length'] = info['query_truncation_length'] + info['top_hit_truncation_length']\n",
    "            info[f'query_terminus'] = 'C' if (query_stop_idx < len(row.query_seq)) else 'none'\n",
    "            info[f'top_hit_terminus'] = 'C' if (top_hit_stop_idx < len(row.top_hit_seq)) else 'none'\n",
    "            df.append(info)\n",
    "\n",
    "    convergent_adjusted_conflict_df += get_best_configurations(pd.DataFrame(df))\n",
    "\n",
    "convergent_adjusted_conflict_df = pd.DataFrame(convergent_adjusted_conflict_df)\n",
    "\n",
    "print('Num. resolved convergent overlaps:', get_num_resolved(convergent_adjusted_conflict_df))\n",
    "assert (convergent_adjusted_conflict_df.modification == 'none').sum() == len(convergent_dataset_df), f'Expected {len(convergent_dataset_df)} unmodified entries, but got {(convergent_adjusted_conflict_df.modification == 'none').sum()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99410e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. divergent conflicts: 33\n"
     ]
    }
   ],
   "source": [
    "# Divergent overlaps\n",
    "\n",
    "# Divergent overlaps conflict at the 5' ends of both genes, so can only be hallucinated by 5' extension of one or both genes. \n",
    "# Whether or not a divergent overlap is hallucinated can be tested by searching for an alternate start site. \n",
    " \n",
    "divergent_dataset_df = dataset_df[is_cds_conflict(dataset_df) & (dataset_df.overlap_type == 'divergent') & ~is_nested(dataset_df)].copy()\n",
    "print('Num. divergent conflicts:', len(divergent_dataset_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf416de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. resolved divergent overlaps: 29\n"
     ]
    }
   ],
   "source": [
    "divergent_adjusted_conflict_df = list()\n",
    "\n",
    "for row in divergent_dataset_df.itertuples():\n",
    "\n",
    "    df = list()\n",
    "    for query_start_idx in get_alternate_starts(row.query_nt_seq, codon_start=row.query_codon_start):\n",
    "        for top_hit_start_idx in get_alternate_starts(row.top_hit_nt_seq, codon_start=row.top_hit_codon_start):\n",
    "            info = {'query_id':row.query_id, 'top_hit_id':row.top_hit_id}\n",
    "            # In order for an overlap to be \"resolved,\" the sum of the alternate start indices needs to exceed the overlap length. \n",
    "            info['query_seq'] = row.query_seq[query_start_idx:]\n",
    "            info['top_hit_seq'] = row.top_hit_seq[top_hit_start_idx:]\n",
    "            info['query_nt_seq'] = row.query_nt_seq[3 * query_start_idx:]\n",
    "            info['top_hit_nt_seq'] = row.top_hit_nt_seq[3 * top_hit_start_idx:]\n",
    "            info[f'query_truncation_length'] = len(row.query_seq) - len(info['query_seq'])\n",
    "            info[f'top_hit_truncation_length'] = len(row.top_hit_seq) - len(info['top_hit_seq'])\n",
    "            info['overlap_length'] = max(0, row.overlap_length - 3 * (info['query_truncation_length'] + info['top_hit_truncation_length']))\n",
    "            info['original_overlap_length'] = row.overlap_length\n",
    "            info['total_truncation_length'] = info['query_truncation_length'] + info['top_hit_truncation_length']\n",
    "            info[f'query_terminus'] = 'N' if (query_start_idx > 0) else 'none'\n",
    "            info[f'top_hit_terminus'] = 'N' if (top_hit_start_idx > 0) else 'none'\n",
    "            df.append(info)\n",
    "\n",
    "    \n",
    "    divergent_adjusted_conflict_df += get_best_configurations(pd.DataFrame(df))\n",
    "\n",
    "divergent_adjusted_conflict_df = pd.DataFrame(divergent_adjusted_conflict_df)\n",
    "\n",
    "print('Num. resolved divergent overlaps:', get_num_resolved(divergent_adjusted_conflict_df)) \n",
    "assert (divergent_adjusted_conflict_df.modification == 'none').sum() == len(divergent_dataset_df), f'Expected {len(divergent_dataset_df)} unmodified entries, but got {(divergent_adjusted_conflict_df.modification == 'none').sum()}'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f457cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. nested conflicts: 85\n",
      "Num. nested overlaps due to fragmentation: 9\n",
      "\n",
      "['NZ_AP025523.1_333', 'NZ_AP025523.1_686', 'NZ_AP025523.1_1533', 'NZ_AP025523.1_3060', 'NZ_CP065383.1_468', 'NZ_NIGF01000018.1_4', 'NZ_NIGF01000027.1_4', 'NZ_NIGF01000006.1_140', 'NC_014960.1_581']\n"
     ]
    }
   ],
   "source": [
    "# Divergent overlaps\n",
    "\n",
    "# Divergent overlaps conflict at the 5' ends of both genes, so can only be hallucinated by 5' extension of one or both genes. \n",
    "# Whether or not a divergent overlap is hallucinated can be tested by searching for an alternate start site. \n",
    " \n",
    "nested_dataset_df = dataset_df[is_cds_conflict(dataset_df) & is_nested(dataset_df)].copy()\n",
    "print('Num. nested conflicts:', len(nested_dataset_df))\n",
    "\n",
    "# BLASTp against NCBI clustered nr database, with the following parameters (default):\n",
    "# Max. target sequences     100\n",
    "# Expect threshold      0.01\n",
    "nested_blast_df = BLASTJsonFile('../data/results/results-2/conflict_nested_blast.json').to_df()\n",
    "\n",
    "nested_dataset_df['fragmented'] = nested_dataset_df.apply(lambda row : is_fragmented(row, blast_df=nested_blast_df), axis=1)\n",
    "print('Num. nested overlaps due to fragmentation:', nested_dataset_df.fragmented.sum(), end='\\n\\n')\n",
    "\n",
    "nested_fragmented_ids = list(nested_dataset_df[nested_dataset_df.fragmented].index)\n",
    "print(nested_fragmented_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85472337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 11 adjusted conflicts which did not reduce overlap length.\n",
      "Num. resolved nested overlaps: 11\n",
      "Num. reduced nested overlaps: 13\n",
      "Num. nested overlaps resolved by C-terminal truncation: 0\n",
      "Num. nested overlaps resolved by N-terminal truncation: 11\n"
     ]
    }
   ],
   "source": [
    "nested_adjusted_conflict_df = list()\n",
    "\n",
    "# Can't just use the overlap length to figure out if an overlap is resolved for nested conflicts, so need to use the start/stop coordinate differences.\n",
    "get_start_delta = lambda row, parent_prefix, daughter_prefix : (row[f'{daughter_prefix}_start'] - row[f'{parent_prefix}_start']) if (row[f'{parent_prefix}_strand'] == 1) else abs(row[f'{parent_prefix}_stop'] - row[f'{daughter_prefix}_stop'])\n",
    "get_stop_delta = lambda row, parent_prefix, daughter_prefix : (row[f'{daughter_prefix}_start'] - row[f'{parent_prefix}_start']) if (row[f'{parent_prefix}_strand'] == -1) else abs(row[f'{parent_prefix}_stop'] - row[f'{daughter_prefix}_stop'])\n",
    "\n",
    "for row in [row.to_dict() for _, row in nested_dataset_df[~nested_dataset_df.fragmented].iterrows()]:\n",
    "    \n",
    "    parent_prefix = 'query' if (row['query_length'] > row['top_hit_length']) else 'top_hit'\n",
    "    daughter_prefix = 'query' if (row['query_length'] < row['top_hit_length']) else 'top_hit'\n",
    "\n",
    "    start_idxs = get_alternate_starts(row[f'{parent_prefix}_nt_seq'], codon_start=row[f'{parent_prefix}_codon_start'])\n",
    "    stop_idxs = get_alternate_stops(row[f'{parent_prefix}_id'], seq=row[f'{parent_prefix}_seq'], blast_df=nested_blast_df)\n",
    "\n",
    "    start_delta = get_start_delta(row, parent_prefix, daughter_prefix)\n",
    "    stop_delta = get_stop_delta(row, parent_prefix, daughter_prefix)\n",
    "    assert (start_delta >= 0), f'start_delta should be positive, but got {start_delta}.'\n",
    "    assert (stop_delta >= 0), f'stop_delta should be positive, but got {stop_delta}.'\n",
    "    \n",
    "    df = list()\n",
    "    for start_idx in start_idxs:\n",
    "        info = {'query_id':row['query_id'], 'top_hit_id':row['top_hit_id'], 'original_overlap_length':row['overlap_length']}\n",
    "        info[f'{parent_prefix}_seq'] = row[f'{parent_prefix}_seq'][start_idx:]\n",
    "        info[f'{parent_prefix}_nt_seq'] = row[f'{parent_prefix}_nt_seq'][3 * start_idx:]\n",
    "        info[f'{daughter_prefix}_seq'] = row[f'{daughter_prefix}_nt_seq']\n",
    "        info[f'{daughter_prefix}_nt_seq'] = row[f'{daughter_prefix}_nt_seq']\n",
    "\n",
    "        info['top_hit_truncation_length'] = len(row['top_hit_seq']) - len(info['top_hit_seq'])\n",
    "        info['query_truncation_length'] = len(row['query_seq']) - len(info['query_seq'])\n",
    "        \n",
    "        total_truncation_length = info['query_truncation_length'] + info['top_hit_truncation_length']\n",
    "\n",
    "        if (start_delta - 3 * total_truncation_length) < 0:\n",
    "            info['overlap_length'] = max(0, row['overlap_length'] + (start_delta - 3 * total_truncation_length))\n",
    "        else:\n",
    "            info['overlap_length'] = row['overlap_length']\n",
    "\n",
    "        info['total_truncation_length'] = total_truncation_length\n",
    "        info[f'{daughter_prefix}_terminus'] = 'none'\n",
    "        info[f'{parent_prefix}_terminus'] = 'N' if (info['total_truncation_length'] > 0) else 'none'\n",
    "        df.append(info)\n",
    "\n",
    "    nested_adjusted_conflict_df += get_best_configurations(pd.DataFrame(df))\n",
    "\n",
    "    for stop_idx in stop_idxs:\n",
    "        info = {'query_id':row['query_id'], 'top_hit_id':row['top_hit_id'], 'original_overlap_length':row['overlap_length']}\n",
    "        info[f'{parent_prefix}_seq'] = row[f'{parent_prefix}_seq'][:stop_idx]\n",
    "        info[f'{parent_prefix}_nt_seq'] = row[f'{parent_prefix}_nt_seq'][:3 * stop_idx]\n",
    "        info[f'{daughter_prefix}_seq'] = row[f'{daughter_prefix}_nt_seq']\n",
    "        info[f'{daughter_prefix}_nt_seq'] = row[f'{daughter_prefix}_nt_seq']\n",
    "\n",
    "        info['top_hit_truncation_length'] = len(row['top_hit_seq']) - len(info['top_hit_seq'])\n",
    "        info['query_truncation_length'] = len(row['query_seq']) - len(info['query_seq'])\n",
    "        \n",
    "        total_truncation_length = info['query_truncation_length'] + info['top_hit_truncation_length']\n",
    "\n",
    "        if (stop_delta - 3 * total_truncation_length) < 0:\n",
    "            info['overlap_length'] = max(0, row['overlap_length'] + (stop_delta - 3 * total_truncation_length))\n",
    "        else:\n",
    "            info['overlap_length'] = row['overlap_length']\n",
    "\n",
    "        info['total_truncation_length'] = total_truncation_length\n",
    "        info[f'{daughter_prefix}_terminus'] = 'none'\n",
    "        info[f'{parent_prefix}_terminus'] = 'C' if (info['total_truncation_length'] > 0) else 'none'\n",
    "        df.append(info)\n",
    "\n",
    "    nested_adjusted_conflict_df += get_best_configurations(pd.DataFrame(df))\n",
    "\n",
    "nested_adjusted_conflict_df = pd.DataFrame(nested_adjusted_conflict_df)\n",
    "nested_adjusted_conflict_df = nested_adjusted_conflict_df.drop_duplicates(subset=['query_id', 'top_hit_id', 'modification'])\n",
    "\n",
    "mask = ((nested_adjusted_conflict_df.modification != 'none') & (nested_adjusted_conflict_df.overlap_length == nested_adjusted_conflict_df.original_overlap_length))\n",
    "print(f'Removing {mask.sum()} adjusted conflicts which did not reduce overlap length.')\n",
    "nested_adjusted_conflict_df = nested_adjusted_conflict_df[~mask].copy()\n",
    "\n",
    "# assert np.all(nested_adjusted_conflict_df.modification != 'both')\n",
    "nested_adjusted_conflict_df['n_terminal_truncation'] = ((nested_adjusted_conflict_df.query_terminus == 'N') | (nested_adjusted_conflict_df.top_hit_terminus == 'N')) & (nested_adjusted_conflict_df.modification != 'both')\n",
    "nested_adjusted_conflict_df['c_terminal_truncation'] = ((nested_adjusted_conflict_df.query_terminus == 'C') | (nested_adjusted_conflict_df.top_hit_terminus == 'C')) & (nested_adjusted_conflict_df.modification != 'both')\n",
    "\n",
    "print('Num. resolved nested overlaps:', get_num_resolved(nested_adjusted_conflict_df))  \n",
    "print('Num. reduced nested overlaps:', (nested_adjusted_conflict_df.overlap_length < nested_adjusted_conflict_df.original_overlap_length).sum())  \n",
    "print('Num. nested overlaps resolved by C-terminal truncation:', get_num_resolved(nested_adjusted_conflict_df[nested_adjusted_conflict_df.c_terminal_truncation]))  \n",
    "print('Num. nested overlaps resolved by N-terminal truncation:', get_num_resolved(nested_adjusted_conflict_df[nested_adjusted_conflict_df.n_terminal_truncation]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "319b11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_conflict_df = list()\n",
    "\n",
    "dfs = dict()\n",
    "dfs['convergent'] = convergent_adjusted_conflict_df\n",
    "dfs['divergent'] = divergent_adjusted_conflict_df\n",
    "dfs['tandem'] = tandem_adjusted_conflict_df\n",
    "dfs['nested'] = nested_adjusted_conflict_df\n",
    "\n",
    "# print(f'len(convergent_adjusted_conflict_df) = {len(convergent_adjusted_conflict_df)}')\n",
    "# print(f'len(divergent_adjusted_conflict_df) = {len(divergent_adjusted_conflict_df)}')\n",
    "# print(f'len(tandem_adjusted_conflict_df) = {len(tandem_adjusted_conflict_df)}')\n",
    "# print(f'len(nested_adjusted_conflict_df) = {len(nested_adjusted_conflict_df)}')\n",
    "\n",
    "get_pair_id = lambda row : '+'.join(sorted([row.top_hit_id, row.query_id]))\n",
    "\n",
    "for overlap_type, df in dfs.items():\n",
    "    for _, row in df.iterrows():\n",
    "        n = 0\n",
    "        for prefix in ['top_hit', 'query']:\n",
    "            info = {key.replace(f'{prefix}_', ''):value for key, value in row.to_dict().items() if (prefix in key)}\n",
    "            info['overlap_type'] = overlap_type\n",
    "            info['overlap_length'] = row.overlap_length\n",
    "            info['original_overlap_length'] = row.original_overlap_length\n",
    "            info['conflict_id'] = getattr(row, 'top_hit_id' if (prefix == 'query') else 'query_id')\n",
    "            info['pair_id'] = get_pair_id(row)\n",
    "            info['modification'] = row.modification\n",
    "            adjusted_conflict_df.append(info)\n",
    "            n += 1\n",
    "        assert n == 2\n",
    "\n",
    "adjusted_conflict_df = pd.DataFrame(adjusted_conflict_df)\n",
    "# There should be at least two entries associated with every pair. \n",
    "adjusted_conflict_df['gc_content'] = adjusted_conflict_df.nt_seq.apply(get_gc_content)\n",
    "adjusted_conflict_df = adjusted_conflict_df.reset_index()\n",
    "adjusted_conflict_df.index.name = 'index'\n",
    "\n",
    "for field in ['genome_id', 'species']:\n",
    "    map_ = {id_:value for id_, value in zip(dataset_df.index, dataset_df[field])}\n",
    "    map_.update({id_:species for id_, species in zip(dataset_df.top_hit_protein_id, dataset_df[field])})\n",
    "    adjusted_conflict_df[field] = adjusted_conflict_df['id'].map(map_)\n",
    "\n",
    "# adjusted_conflict_df = adjusted_conflict_df.drop_duplicates(subset=['id', 'terminus'])\n",
    "adjusted_conflict_df = adjusted_conflict_df.drop_duplicates(subset=['seq', 'pair_id'])\n",
    "adjusted_conflict_df.set_index('index').to_csv('../data/results/results-2/adjusted_conflict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a9e10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. conflicts (not including fragments): 449\n",
      "Num. resolvable conflicts (not including fragments): 198\n",
      "Num. conflicts resolvable by N-terminal truncation: 150\n",
      "Num. conflicts resolvable by C-terminal truncation: 52\n",
      "Num. irresolvable conflicts: 251\n"
     ]
    }
   ],
   "source": [
    "df = adjusted_conflict_df[(adjusted_conflict_df.overlap_length == 0)].copy()\n",
    "resolvable_pair_ids = df.pair_id.unique()\n",
    "\n",
    "print('Num. conflicts (not including fragments):', adjusted_conflict_df.pair_id.nunique())\n",
    "print('Num. resolvable conflicts (not including fragments):', df.pair_id.nunique())\n",
    "print('Num. conflicts resolvable by N-terminal truncation:', (df[(df.terminus == 'N') & (df.modification != 'both')].drop_duplicates('pair_id').overlap_length == 0).sum())\n",
    "print('Num. conflicts resolvable by C-terminal truncation:',  (df[(df.terminus == 'C') & ((df.modification != 'both'))].drop_duplicates('pair_id').overlap_length == 0).sum())\n",
    "\n",
    "print('Num. irresolvable conflicts:', (~np.isin(adjusted_conflict_df.pair_id.unique(), resolvable_pair_ids)).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9809bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 334.646x250.984 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "is_annotated_match = lambda df : df.match & (df.top_hit_product != 'hypothetical protein') & (~df.top_hit_pseudo) & (df.top_hit_evidence_type == 'similar to AA sequence')\n",
    "is_annotated_exact_match = lambda df : df.exact_match & (df.top_hit_product != 'hypothetical protein') & (~df.top_hit_pseudo) & (df.top_hit_evidence_type == 'similar to AA sequence')\n",
    "is_n_terminal_extension = lambda df : (((df.query_start < df.top_hit_start) & (df.query_strand  == 1)) | ((df.query_stop > df.top_hit_stop) & (df.query_strand  == -1))) & df.match\n",
    "is_annotated_n_terminal_extension = lambda df : is_n_terminal_extension(df) & is_annotated_match(df)\n",
    "\n",
    "def figure(dataset_df:pd.DataFrame):\n",
    "\n",
    "    fig, ax = get_figure() \n",
    "\n",
    "    dimonaco_df = pd.read_csv('../data/dimonaco_2020.csv') # Load in data from \"No one tool to rule them all\" paper.\n",
    "    dimonaco_df['n_terminal_extension_rate'] = dimonaco_df.num_n_terminal_extension / dimonaco_df.num_match\n",
    "    dimonaco_df['n_terminal_extension_rate'] = dimonaco_df.num_n_terminal_extension / dimonaco_df.num_match\n",
    "    dimonaco_df['n_terminal_truncation_rate'] = (dimonaco_df.num_match - (dimonaco_df.num_perfect_starts + dimonaco_df.num_n_terminal_extension)) / dimonaco_df.num_match\n",
    "\n",
    "    palette = {'Prodigal':'gray', 'GeneMarkS-2':'lightgray'}\n",
    "    sns.scatterplot(dimonaco_df, x='gc_content', y='n_terminal_extension_rate', hue='tool', legend=True, palette=palette, edgecolor='black', lw=1)\n",
    "    # sns.scatterplot(dimonaco_df, x='gc_content', y='n_terminal_truncation_rate', hue='tool', marker='v', legend=False, s=50, palette=palette)\n",
    "\n",
    "    figure_df = pd.DataFrame(index=pd.Index(dataset_df.species.unique()))\n",
    "    figure_df['num_n_terminal_extension'] = dataset_df[is_annotated_n_terminal_extension(dataset_df)].groupby('species').apply(len, include_groups=False)\n",
    "    figure_df['total'] = dataset_df[is_annotated_match(dataset_df)].groupby('species').apply(len, include_groups=False)\n",
    "    figure_df['gc_content'] = dataset_df.groupby('species').gc_percent.first()\n",
    "    figure_df['n_terminal_extension_rate'] = dataset_df.groupby('species').apply(lambda df : is_annotated_n_terminal_extension(df).sum() / is_annotated_match(df).sum(), include_groups=False)\n",
    "\n",
    "    sns.scatterplot(figure_df, x='gc_content', y='n_terminal_extension_rate', color='black', legend=True, s=10)\n",
    "    save_figure(fig)\n",
    "\n",
    "\n",
    "figure(dataset_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44466fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 334.646x250.984 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def figure(dataset_df:pd.DataFrame, adjusted_conflict_df:pd.DataFrame):\n",
    "\n",
    "    figure_df = pd.DataFrame(index=pd.Index(dataset_df.species.unique()))\n",
    "    figure_df['gc_content'] = dataset_df.groupby('species').top_hit_gc_content.first()\n",
    "\n",
    "    fig, ax = get_figure()\n",
    "\n",
    "    # Select the sequences which can be truncated at the N-terminus to resolve the conflict. \n",
    "    adjusted_conflict_df = adjusted_conflict_df[(adjusted_conflict_df.terminus == 'N') & (adjusted_conflict_df.overlap_length == 0)].copy()\n",
    "    adjusted_conflict_df['truncation_length'] = (adjusted_conflict_df.truncation_length)\n",
    "    dataset_df = dataset_df[is_annotated_match(dataset_df) & is_n_terminal_extension(dataset_df) & (dataset_df.top_hit_evidence_type == 'similar to AA sequence')].copy()\n",
    "    dataset_df['truncation_length'] = (dataset_df.apply(get_n_terminal_extension_length, axis=1))\n",
    "\n",
    "    figure_df['ref_n_terminal_extension_count'] = dataset_df.groupby('species').apply(len, include_groups=False)\n",
    "    figure_df['ref_n_terminal_extension_length_mean'] = dataset_df.groupby('species').truncation_length.mean()\n",
    "    figure_df['ref_n_terminal_extension_length_std'] = dataset_df.groupby('species').truncation_length.std()\n",
    "    figure_df['ref_n_terminal_extension_length_err'] = figure_df['ref_n_terminal_extension_length_std'] / np.sqrt(figure_df.ref_n_terminal_extension_count)\n",
    "\n",
    "    figure_df['n_terminal_extension_count'] = adjusted_conflict_df.groupby('species').apply(len, include_groups=False)\n",
    "    figure_df['n_terminal_extension_length_mean'] = adjusted_conflict_df.groupby('species').truncation_length.mean()\n",
    "    figure_df['n_terminal_extension_length_std'] = adjusted_conflict_df.groupby('species').truncation_length.std()\n",
    "    figure_df['n_terminal_extension_length_err'] = figure_df['n_terminal_extension_length_std'] / np.sqrt(figure_df.n_terminal_extension_count)\n",
    "\n",
    "    sns.scatterplot(figure_df, x='gc_content', y='ref_n_terminal_extension_length_mean', color='gray', label='reference', ax=ax)\n",
    "    # sns.scatterplot(figure_df, x='gc_content', y='n_terminal_extension_length_mean', color='lightgray', label='conflict', ax=ax)\n",
    "\n",
    "    ax.errorbar(figure_df.gc_content, figure_df.ref_n_terminal_extension_length_mean, yerr=figure_df.ref_n_terminal_extension_length_err, ls='', lw=0.7, color='gray', capsize=2, zorder=10)\n",
    "    # ax.errorbar(figure_df.gc_content, figure_df.n_terminal_extension_length_mean, yerr=figure_df.n_terminal_extension_length_err, ls='', lw=0.7, color='lightgray', capsize=2, zorder=10)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.set_ylabel('extension_length')\n",
    "        \n",
    "    save_figure(fig)\n",
    "\n",
    "figure(dataset_df, adjusted_conflict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27048da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=0.44619\n"
     ]
    }
   ],
   "source": [
    "# Want to establish that there is apparently no connection between whether or not a gene is N-terminally extended and the GC content of the gene. \n",
    "\n",
    "df = dataset_df[is_annotated_exact_match(dataset_df) | is_annotated_n_terminal_extension(dataset_df)].copy()\n",
    "df['category'] = np.select([is_annotated_exact_match(df), is_annotated_n_terminal_extension(df)], ['exact_match', 'n_terminal_extension'], default='none')\n",
    "df['genome_gc_content'] = df.species.map(df.groupby('species').gc_percent.first())\n",
    "df['gc_content'] = df.top_hit_nt_seq.apply(get_gc_content)\n",
    "df['gc_content_normalized'] = df.top_hit_nt_seq.apply(get_gc_content) / df.genome_gc_content\n",
    "\n",
    "p = mannwhitneyu(df[df.category == 'exact_match'].gc_content_normalized.values, df[df.category == 'n_terminal_extension'].gc_content_normalized.values).pvalue\n",
    "print(f'p={p:.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "002ef542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def figure(adjusted_conflict_df:pd.DataFrame, exclude_nested:bool=True):\n",
    "\n",
    "#     resolvable_ids = adjusted_conflict_df[adjusted_conflict_df.overlap_length == 0]['id'].values \n",
    "\n",
    "#     is_resolvable_conflict = lambda df : df.top_hit_id.isin(resolvable_ids) | df.query_id.isin(resolvable_ids)\n",
    "\n",
    "#     figure_df = dataset_df[is_cds_conflict(dataset_df)].copy()\n",
    "#     if exclude_nested:\n",
    "#         figure_df = figure_df[~is_nested(figure_df)].copy()\n",
    "\n",
    "#     figure_df['resolvable'] = is_resolvable_conflict(figure_df)\n",
    "#     figure_df['category'] = np.where(figure_df.resolvable, 'resolvable', 'irresolvable')\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "#     palette = {'resolvable':'gray', 'irresolvable':'lightgray'}\n",
    "#     sns.ecdfplot(figure_df[~figure_df.same_strand], x='overlap_length', hue='category', palette=palette, ls=':')\n",
    "#     sns.ecdfplot(figure_df[figure_df.same_strand], x='overlap_length', hue='category', palette=palette)\n",
    "\n",
    "#     overlap_length = 30\n",
    "#     ax.axvline(overlap_length, ls='--', color='black', lw=0.7)\n",
    "\n",
    "#     text = get_text(f'tandem > {overlap_length}', (figure_df.same_strand & ~figure_df.resolvable & (figure_df.overlap_length > overlap_length)).sum(), figure_df.same_strand.sum())\n",
    "#     text += get_text(f'antiparallel > {overlap_length}', (~figure_df.same_strand & ~figure_df.resolvable & (figure_df.overlap_length > overlap_length)).sum(), (~figure_df.same_strand).sum())\n",
    "#     ax.text(0.5, 0.5, text, transform=ax.transAxes)\n",
    "#     ax.set_ylabel('proportion')\n",
    "\n",
    "#     ax.set_xlim(xmax=300, xmin=0)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# figure(adjusted_conflict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "021a61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def figure(dataset_df:pd.DataFrame, adjusted_conflict_df:pd.DataFrame):\n",
    "\n",
    "#     figure_df = pd.DataFrame(index=pd.Index(dataset_df.species.unique()))\n",
    "#     figure_df['annotated_match_gc_content'] = dataset_df[is_annotated_match(dataset_df)].groupby('species').top_hit_gc_content.mean()\n",
    "#     figure_df['genome_gc_content'] = dataset_df[is_annotated_match(dataset_df)].groupby('species').gc_percent.first() / 100\n",
    "#     figure_df['annotated_exact_match_gc_content'] = dataset_df[is_annotated_exact_match(dataset_df)].groupby('species').top_hit_gc_content.mean()\n",
    "\n",
    "#     fig, axes = plt.subplots(figsize=(10, 5), ncols=2)\n",
    "\n",
    "#     # Select the sequences which can be truncated at the N-terminus to resolve the conflict. \n",
    "#     adjusted_conflict_df = adjusted_conflict_df[(adjusted_conflict_df.terminus == 'N') & (adjusted_conflict_df.overlap_length == 0)].copy()\n",
    "#     # adjusted_conflict_df['truncation_length'] = np.log10(adjusted_conflict_df.truncation_length)\n",
    "#     adjusted_conflict_df['truncation_length'] = (adjusted_conflict_df.truncation_length)\n",
    "#     dataset_df = dataset_df[is_annotated_match(dataset_df) & is_n_terminal_extension(dataset_df)].copy()\n",
    "#     dataset_df = dataset_df.rename(columns={'top_hit_gc_content':'gc_content'})\n",
    "#     # dataset_df['truncation_length'] = np.log10(dataset_df.apply(get_n_terminal_extension_length, axis=1))\n",
    "#     dataset_df['truncation_length'] = (dataset_df.apply(get_n_terminal_extension_length, axis=1))\n",
    "\n",
    "#     for ax, var in zip(axes, ['gc_content', 'truncation_length']):\n",
    "\n",
    "\n",
    "#         figure_df['annotated_n_terminal_extension_count'] = dataset_df.groupby('species').apply(len, include_groups=False)\n",
    "#         figure_df[f'annotated_n_terminal_extension_{var}_mean'] = dataset_df.groupby('species').truncation_length.mean()\n",
    "#         figure_df[f'annotated_n_terminal_extension_{var}_std'] = dataset_df.groupby('species').truncation_length.std()\n",
    "#         figure_df[f'annotated_n_terminal_extension_{var}_err'] = figure_df[f'annotated_n_terminal_extension_{var}_std'] / np.sqrt(figure_df.annotated_n_terminal_extension_count)\n",
    "\n",
    "#         figure_df['conflict_n_terminal_extension_count'] = adjusted_conflict_df.groupby('species').apply(len, include_groups=False)\n",
    "#         figure_df[f'conflict_n_terminal_extension_{var}_mean'] = adjusted_conflict_df.groupby('species').truncation_length.mean()\n",
    "#         figure_df[f'conflict_n_terminal_extension_{var}_std'] = adjusted_conflict_df.groupby('species').truncation_length.std()\n",
    "#         figure_df[f'conflict_n_terminal_extension_{var}_err'] = figure_df[f'conflict_n_terminal_extension_{var}_std'] / np.sqrt(figure_df.conflict_n_terminal_extension_count)\n",
    "\n",
    "    \n",
    "#         sns.scatterplot(figure_df, x=f'genome_gc_content', y=f'annotated_n_terminal_extension_{var}_mean', color='gray', label='reference', ax=ax)\n",
    "#         ax.errorbar(figure_df['genome_gc_content'], figure_df[f'annotated_n_terminal_extension_{var}_mean'], yerr=figure_df[f'annotated_n_terminal_extension_{var}_err'], ls='', lw=0.7, color='gray', capsize=2, zorder=10)\n",
    "#         sns.scatterplot(figure_df, x='genome_gc_content', y=f'conflict_n_terminal_extension_{var}_mean', color='lightgray', label='conflict', ax=ax)\n",
    "#         ax.errorbar(figure_df['genome_gc_content'], figure_df[f'conflict_n_terminal_extension_{var}_mean'], yerr=figure_df[f'conflict_n_terminal_extension_{var}_err'], ls='', lw=0.7, color='lightgray', capsize=2, zorder=10)\n",
    "        \n",
    "#         if var == 'gc_content':\n",
    "#             sns.lineplot(x=np.linspace(0.3, 0.7, 10), y=np.linspace(0.3, 0.7, 10), ls='--', color='black', lw=0.7, ax=ax)\n",
    "\n",
    "#         ax.legend()\n",
    "#         ax.set_ylabel(var)\n",
    "        \n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# figure(dataset_df, adjusted_conflict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81a54473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I also want to check on the strength of the ribosome binding sites, also normalized relative to genome RBS binding strength. \n",
    "# # Will use this instead of presence/absence to have continuous values, as well as account for genome differences more easily. \n",
    "\n",
    "# if ('query_rbs_min_free_energy' not in dataset_df.columns) or ('top_hit_rbs_min_free_energy' not in dataset_df.columns):\n",
    "#     rnacofold = RNACoFold()\n",
    "#     query_rnacofold_df = rnacofold.run(dataset_df, seq_col='query_nt_seq_upstream')\n",
    "#     top_hit_rnacofold_df = rnacofold.run(dataset_df, seq_col='top_hit_nt_seq_upstream')\n",
    "#     rnacofold.cleanup()\n",
    "    \n",
    "#     dataset_df['query_rbs_min_free_energy'] = query_rnacofold_df.mfe\n",
    "#     dataset_df['top_hit_rbs_min_free_energy'] = top_hit_rnacofold_df.mfe\n",
    "\n",
    "#     df = pd.read_csv('../data/results/results-2/dataset.csv', index_col=0)\n",
    "#     df['query_rbs_min_free_energy'] = query_rnacofold_df.mfe\n",
    "#     df['top_hit_rbs_min_free_energy'] = top_hit_rnacofold_df.mfe\n",
    "#     df.to_csv('../data/results/results-2/dataset.csv')\n",
    "    \n",
    "\n",
    "# df = dataset_df[is_annotated_exact_match(dataset_df) | is_annotated_n_terminal_extension(dataset_df)].copy()\n",
    "# df['rbs_min_free_energy'] = df.query_rbs_min_free_energy\n",
    "# df['category'] = np.select([is_annotated_exact_match(df), is_annotated_n_terminal_extension(df)], ['exact_match', 'n_terminal_extension'], default='none')\n",
    "# df = df[['species', 'rbs_min_free_energy', 'category']].copy()\n",
    "\n",
    "# mask = (adjusted_conflict_df.terminus == 'N') & (adjusted_conflict_df.overlap_length == 0)\n",
    "# df = pd.concat([adjusted_conflict_df[mask][['rbs_min_free_energy', 'species']].assign(category='conflict'), df], axis=0)\n",
    "\n",
    "# df['genome_rbs_min_free_energy'] = df.species.map(df.groupby('species').rbs_min_free_energy.mean())\n",
    "# df['rbs_min_free_energy_normalized'] = df.rbs_min_free_energy / df.genome_rbs_min_free_energy\n",
    "\n",
    "# # p = mannwhitneyu(df[df.category == 'exact_match'].rbs_min_free_energy_normalized.values, df[df.category == 'n_terminal_extension'].rbs_min_free_energy_normalized.values).pvalue\n",
    "# p = mannwhitneyu(df[df.category == 'exact_match'].rbs_min_free_energy.values, df[df.category == 'n_terminal_extension'].rbs_min_free_energy.values).pvalue\n",
    "# print(f'p={p:.7f}', end='\\n\\n')\n",
    "\n",
    "# p = mannwhitneyu(df[df.category == 'n_terminal_extension'].rbs_min_free_energy.values, df[df.category == 'conflict'].rbs_min_free_energy_normalized.values).pvalue\n",
    "# print(f'p={p:.7f}')\n",
    "\n",
    "# # We do observe a statistically-significant difference in the RBS strength; sequences which are N-terminally extended tend to have\n",
    "# # weaker RBS. One potential explanation for this is that the original sequences lack an RBS, so Prodigal looks for the \"best\" RBS it can find, \n",
    "# # resulting in erroneous start-site selection. \n",
    "\n",
    "# # fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# # sns.ecdfplot(df, x='rbs_min_free_energy_normalized', hue='category', palette={'exact_match':'black', 'conflict':'indianred', 'n_terminal_extension':'gray'})\n",
    "# # ax.set_xlim(xmin=0, xmax=3)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36c4182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure_df = pd.DataFrame(index=pd.Index(dataset_df.species.unique()))\n",
    "# figure_df['genome_rbs_min_free_energy'] = dataset_df[is_annotated_exact_match(dataset_df)].groupby('species').query_rbs_min_free_energy.mean()\n",
    "\n",
    "# figure_df['reference_n_terminal_extension_rbs_min_free_energy_count'] = dataset_df[is_annotated_n_terminal_extension(dataset_df)].groupby('species').size()\n",
    "# figure_df['reference_n_terminal_extension_rbs_min_free_energy_mean'] = dataset_df[is_annotated_n_terminal_extension(dataset_df)].groupby('species').query_rbs_min_free_energy.mean()\n",
    "# figure_df['reference_n_terminal_extension_rbs_min_free_energy_std'] = dataset_df[is_annotated_n_terminal_extension(dataset_df)].groupby('species').query_rbs_min_free_energy.std()\n",
    "# figure_df['reference_n_terminal_extension_rbs_min_free_energy_err'] = figure_df.reference_n_terminal_extension_rbs_min_free_energy_std / np.sqrt(figure_df.reference_n_terminal_extension_rbs_min_free_energy_count)\n",
    "\n",
    "# figure_df['conflict_n_terminal_extension_rbs_min_free_energy_count'] = adjusted_conflict_df[(adjusted_conflict_df.terminus == 'N') & (adjusted_conflict_df.overlap_length == 0)].groupby('species').size()\n",
    "# figure_df['conflict_n_terminal_extension_rbs_min_free_energy_mean'] = adjusted_conflict_df[(adjusted_conflict_df.terminus == 'N') & (adjusted_conflict_df.overlap_length == 0)].groupby('species').rbs_min_free_energy.mean()\n",
    "# figure_df['conflict_n_terminal_extension_rbs_min_free_energy_std'] = adjusted_conflict_df[(adjusted_conflict_df.terminus == 'N') & (adjusted_conflict_df.overlap_length == 0)].groupby('species').rbs_min_free_energy.std()\n",
    "# figure_df['conflict_n_terminal_extension_rbs_min_free_energy_err'] = figure_df.conflict_n_terminal_extension_rbs_min_free_energy_std / np.sqrt(figure_df.conflict_n_terminal_extension_rbs_min_free_energy_count)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# sns.scatterplot(figure_df, x='genome_rbs_min_free_energy', y='reference_n_terminal_extension_rbs_min_free_energy_mean', color='black')\n",
    "# sns.scatterplot(figure_df, x='genome_rbs_min_free_energy', y='conflict_n_terminal_extension_rbs_min_free_energy_mean', color='indianred')\n",
    "# sns.lineplot(x=np.linspace(-10, -2, 10), y=np.linspace(-10, -2, 10), ls='--', color='black', lw=0.7)\n",
    "\n",
    "# ax.errorbar(figure_df['genome_rbs_min_free_energy'], figure_df[f'reference_n_terminal_extension_rbs_min_free_energy_mean'], yerr=figure_df[f'reference_n_terminal_extension_rbs_min_free_energy_err'], ls='', lw=0.7, color='black', capsize=2, zorder=10)\n",
    "# ax.errorbar(figure_df['genome_rbs_min_free_energy'], figure_df[f'conflict_n_terminal_extension_rbs_min_free_energy_mean'], yerr=figure_df[f'conflict_n_terminal_extension_rbs_min_free_energy_err'], ls='', lw=0.7, color='indianred', capsize=2, zorder=10)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0108018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure_df = pd.DataFrame(index=pd.Index(dataset_df.species.unique(), name='genome_id'))\n",
    "# figure_df['gc_percent'] = dataset_df.groupby('species').gc_percent.first() / 100\n",
    "# figure_df['genome_size'] = dataset_df.groupby('species').apply(len, include_groups=False)\n",
    "# figure_df['n_annotated_match'] = dataset_df.groupby('species').apply(lambda df : is_annotated_match(df).sum(), include_groups=False)\n",
    "# figure_df['n_cds_conflicts'] = dataset_df.groupby('species').apply(lambda df : is_cds_conflict(df).sum(), include_groups=False)\n",
    "# # figure_df['false_positive_rate'] = dataset_df.groupby('species').apply(lambda df : (~df.match).sum() / len(df), include_groups=False)\n",
    "# figure_df['n_annotated_match_with_rbs'] = dataset_df.groupby('species').apply(lambda df : (is_annotated_match(df) & df.query_rbs_motif).sum(), include_groups=False)\n",
    "# figure_df['rbs_content'] = figure_df.n_annotated_match_with_rbs / figure_df.n_annotated_match\n",
    "# figure_df['n_terminal_extension_rate'] = dataset_df.groupby('species').apply(lambda df : is_n_terminal_extension(df).sum() / is_annotated_match(df).sum(), include_groups=False)\n",
    "\n",
    "# figure_df['n_tandem_conflicts'] = tandem_dataset_df.groupby('species').apply(len, include_groups=False) \n",
    "# figure_df['n_divergent_conflicts'] = divergent_dataset_df.groupby('species').apply(len, include_groups=False)\n",
    "# figure_df['n_convergent_conflicts'] = convergent_dataset_df.groupby('species').apply(len, include_groups=False)\n",
    "\n",
    "# for overlap_type in ['tandem', 'convergent', 'divergent']:\n",
    "#     figure_df[f'n_{overlap_type}_conflicts_normalized'] = figure_df[f'n_{overlap_type}_conflicts'] / figure_df.n_cds_conflicts\n",
    "\n",
    "# figure_df = figure_df.fillna(0)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# palette = {'convergent':'gray', 'tandem':'lightgray', 'divergent':'black'}\n",
    "\n",
    "# x = 'gc_percent'\n",
    "\n",
    "# text = '' \n",
    "\n",
    "# for overlap_type in ['tandem', 'convergent', 'divergent']:\n",
    "#     r = np.corrcoef(figure_df[x].values.ravel(), figure_df[f'n_{overlap_type}_conflicts_normalized'].values.ravel())[0, 1] ** 2\n",
    "#     text += r'$R^2_{' + overlap_type + '}$ = ' + f'{r:.2f}\\n'\n",
    "#     # sns.scatterplot(figure_df, x=x, y=f'n_{overlap_type}_conflicts_normalized', ax=ax, label=overlap_type, c=palette[overlap_type])\n",
    "#     sns.scatterplot(figure_df, x=x, y=f'n_{overlap_type}_conflicts', ax=ax, label=overlap_type, c=palette[overlap_type])\n",
    "\n",
    "# ax.text(0.5, 0.5, text, transform=ax.transAxes)\n",
    "# ax.set_ylabel('count')\n",
    "# ax.legend()\n",
    "# sns.move_legend(ax, loc='upper left')\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab882e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def figure(tandem_dataset_df:pd.DataFrame):\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "#     palette = {'none':'indianred', 'c_terminal_extension':'lightgray', 'n_terminal_extension':'gray', 'fragmented':'black'}\n",
    "\n",
    "#     for category, df in tandem_dataset_df.groupby('category'):\n",
    "#         sns.ecdfplot(df, x='overlap_length', c=palette[category], ls=':' if (category == 'fragmented') else '-', label=f'{category} (n={len(df)})', ax=ax)\n",
    "#     ax.legend()\n",
    "\n",
    "#     n = ((tandem_dataset_df.category == 'none') & (tandem_dataset_df.overlap_length > 30)).sum() \n",
    "#     text = '$n_{none > 30} =$' + str(n) + f' ({get_percent(n, (tandem_dataset_df.category == 'none').sum())})'\n",
    "#     n = ((tandem_dataset_df.category == 'none') & (tandem_dataset_df.overlap_length <5)).sum() \n",
    "#     text += '\\n$n_{none < 5} =$' + str(n) + f' ({get_percent(n, (tandem_dataset_df.category == 'none').sum())})'\n",
    "\n",
    "#     ax.text(0.5, 0.5, text, transform=ax.transAxes)\n",
    "#     ax.set_ylabel('proportion')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# figure(tandem_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a0d329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def figure(dataset_df, adjusted_conflict_df):\n",
    "\n",
    "#     dataset_df['rbs_min_free_energy'] = dataset_df.query_rbs_min_free_energy\n",
    "#     adjusted_conflict_df = adjusted_conflict_df[(adjusted_conflict_df.terminus == 'N') & (adjusted_conflict_df.overlap_length == 0)].copy()\n",
    "\n",
    "#     species = adjusted_conflict_df.groupby('species').size().sort_values(ascending=False).index[:5]\n",
    "#     # species = dataset_df[is_annotated_exact_match(dataset_df)].groupby('species').rbs_min_free_energy.mean().sort_values(ascending=True).index[:5]\n",
    "#     adjusted_conflict_df = adjusted_conflict_df[adjusted_conflict_df.species.isin(species)].copy()\n",
    "#     dataset_df = dataset_df[dataset_df.species.isin(species)].copy()\n",
    "    \n",
    "#     dfs = dict()\n",
    "#     dfs['reference_exact_match'] = dataset_df[is_annotated_exact_match(dataset_df)]\n",
    "#     dfs['reference_n_terminal_extension'] = dataset_df[is_annotated_n_terminal_extension(dataset_df)]\n",
    "#     dfs['conflict'] = adjusted_conflict_df\n",
    "\n",
    "#     figure_df = list()\n",
    "#     for category, df in dfs.items():\n",
    "#         figure_df.append(df[['species', 'rbs_min_free_energy']].copy().assign(category=category))\n",
    "#     figure_df = pd.concat(figure_df)\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(10, 5))\n",
    "#     palette = {'reference_exact_match':'darkseagreen', 'reference_n_terminal_extension':'lightgray', 'conflict':'indianred'}\n",
    "#     sns.violinplot(figure_df, hue='category', x='species', y='rbs_min_free_energy', palette=palette, ax=ax, inner='box', common_norm=False)\n",
    "#     ax.set_xticks(ax.get_xticks(), labels=ax.get_xticklabels(), rotation=90)\n",
    "#     plt.show()\n",
    "\n",
    "# figure(dataset_df, adjusted_conflict_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd5306e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc42070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sprout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
